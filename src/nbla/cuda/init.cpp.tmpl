
// Copyright 2018,2019,2020,2021 Sony Corporation.
// Copyright 2021 Sony Group Corporation.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// *WARNING*
// THIS FILE IS AUTO-GENERATED BY CODE GENERATOR.
// PLEASE DO NOT EDIT THIS FILE BY HAND!
// If you want to modify this file, edit following files.
// - src/nbla/cuda/init.cpp.tmpl
// - code_generator/generate.py

#include <nbla/init.hpp>
#include <nbla/cuda/init.hpp>
#include <nbla/cuda/cuda.hpp>
#include <nbla/cuda/common.hpp>
#include <nbla/array_registry.hpp>
#include <nbla/utils/dlpack_array_registry.hpp>
#include <nbla/function_registry.hpp>
#include <nbla/array/cpu_array.hpp>
#include <nbla/cuda/array/cuda_array.hpp>
#include <nbla/cuda/array/cuda_dlpack_array.hpp>
#include <nbla/backend_registry.hpp>

// Todo: avoid including cudnn.h in cuda package.
#include <cudnn.h>

% for name, snake_name, _ in function_list:
% if name in function_types:
#include <nbla/cuda/function/${snake_name}.hpp>
% endif
% endfor
#include <nbla/solver_registry.hpp>
% for name, snake_name, _ in solver_list:
% if name in solver_types:
#include <nbla/cuda/solver/${snake_name}.hpp>
% endif
% endfor


#ifdef FEATURE_DIST_TRAIN
  #include <nbla/cuda/communicator/data_parallel_communicator.hpp>
  #include <nbla/cuda/communicator/multi_process_data_parallel_communicator.hpp>
#endif

#include <nbla/garbage_collector.hpp>

#include <mutex>

namespace nbla {

void init_cuda() {
  static std::mutex mtx;
  std::lock_guard<std::mutex> lock(mtx);

  static volatile bool is_initialized = false;
  if (is_initialized)
    return;

  // Init CPU features
  init_cpu();

  // Set NVIDIA_TF32_OVERRIDE based on NNABLA_CUDA_ALLOW_TF32.
  // NNabla does not use TF32 as defalut.
  const char* allow_tf32 = std::getenv("NNABLA_CUDA_ALLOW_TF32");
  if (!allow_tf32 || strcmp(allow_tf32, "0") == 0) {
    nbla_setenv("NVIDIA_TF32_OVERRIDE", "0");
  } else {
    nbla_setenv("NVIDIA_TF32_OVERRIDE", "1");
  }

  // Init Cuda Driver API
  NBLA_CUDA_DRIVER_CHECK(cuInit(0));

  // Backend registration
  NBLA_REGISTER_BACKEND("cuda", []() { return SingletonManager::get<Cuda>(); });

  // Array registration
  // CudaArray
  NBLA_REGISTER_ARRAY_CREATOR(CudaArray);
  SingletonManager::get<Cuda>()->register_array_class("CudaArray");
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuArray, CudaArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaArray, CpuArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuCachedArray, CudaArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaArray, CpuCachedArray,
                                   synchronizer_cuda_array_cpu_array);
  // one-way
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuDlpackArray, CudaArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_GROUP(CudaArray, cuda);

  // CudaCachedArray
  NBLA_REGISTER_ARRAY_CREATOR(CudaCachedArray);
  SingletonManager::get<Cuda>()->register_array_class("CudaCachedArray");
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuArray, CudaCachedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedArray, CpuArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuCachedArray, CudaCachedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedArray, CpuCachedArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedArray, CudaArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaArray, CudaCachedArray,
                                   synchronizer_default);
  // one-way
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuDlpackArray, CudaCachedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_GROUP(CudaCachedArray, cuda);

  // CudaDlpackArray
  NBLA_REGISTER_ARRAY_CREATOR(CudaDlpackArray);
  SingletonManager::get<Cuda>()->register_array_class("CudaDlpackArray");
  NBLA_REGISTER_DLPACK_DEVICE_TYPE_TO_CONTEXT(kDLGPU, cuda, CudaDlpackArray);
  NBLA_REGISTER_ARRAY_TO_DLPACK_DEVICE_TYPE(CudaArray, kDLGPU);
  NBLA_REGISTER_ARRAY_TO_DLPACK_DEVICE_TYPE(CudaCachedArray, kDLGPU);
  // DlpackArray can be convert one-way.
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaDlpackArray, CpuArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaDlpackArray, CpuCachedArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaDlpackArray, CudaArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaDlpackArray, CudaCachedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_GROUP(CudaDlpackArray, cuda);

  // CudaCachedUnifuedArray
  NBLA_REGISTER_ARRAY_CREATOR(CudaCachedUnifiedArray);
  SingletonManager::get<Cuda>()->register_array_class("CudaCachedUnifiedArray");
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuArray, CudaCachedUnifiedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedUnifiedArray, CpuArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuCachedArray, CudaCachedUnifiedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedUnifiedArray, CpuCachedArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaArray, CudaCachedUnifiedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedUnifiedArray, CudaArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedArray, CudaCachedUnifiedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedUnifiedArray, CudaCachedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_GROUP(CudaCachedUnifiedArray, cuda);

  // CudaCachedHostArray
  NBLA_REGISTER_ARRAY_CREATOR(CudaCachedHostArray);
  SingletonManager::get<Cpu>()->register_array_class("CudaCachedHostArray");
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuArray, CudaCachedHostArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedHostArray, CpuArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuCachedArray, CudaCachedHostArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedHostArray, CpuCachedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaArray, CudaCachedHostArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedHostArray, CudaArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedArray, CudaCachedHostArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedHostArray, CudaCachedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedUnifiedArray, CudaCachedHostArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedHostArray, CudaCachedUnifiedArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_GROUP(CudaCachedHostArray, cpu);

  // CudaCachedVirtualArray
#if CUDA_VERSION >= 10020 && CUDNN_VERSION >= 8000
  NBLA_REGISTER_ARRAY_CREATOR(CudaCachedVirtualArray);
  SingletonManager::get<Cuda>()->register_array_class("CudaCachedVirtualArray");
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuArray, CudaCachedVirtualArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedVirtualArray, CpuArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CpuCachedArray, CudaCachedVirtualArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedVirtualArray, CpuCachedArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaArray, CudaCachedVirtualArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedVirtualArray, CudaArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedArray, CudaCachedVirtualArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedVirtualArray, CudaCachedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedUnifiedArray, CudaCachedVirtualArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedVirtualArray, CudaCachedUnifiedArray,
                                   synchronizer_default);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedHostArray, CudaCachedVirtualArray,
                                   synchronizer_cpu_array_cuda_array);
  NBLA_REGISTER_ARRAY_SYNCHRONIZER(CudaCachedVirtualArray, CudaCachedHostArray,
                                   synchronizer_cuda_array_cpu_array);
  NBLA_REGISTER_ARRAY_GROUP(CudaCachedVirtualArray, cuda);
#endif //CUDA_VERSION >= 10020 && CUDNN_VERSION >= 8000

  // Function registration
% for name, _, arg_types in function_list:
  % for type_config, ttypes in function_types.get(name, {}).items():
    <%
    ttype_args = ', '.join(ttypes)
    ttype_symbol = ''.join(map(lambda x: x.replace(' ', ''), ttypes))
    function_sym = '{}{}<{}>'.format(name, "Cuda", ttype_args)
    function_typed_sym = '{}{}_{}'.format(name, "Cuda", ttype_symbol)
    %> 
  using ${function_typed_sym} = ${function_sym};
  NBLA_REGISTER_FUNCTION_IMPL(${name}, ${function_typed_sym}, "cuda:${type_config}"${''.join(map(lambda x: ', ' + x, arg_types))});
  % endfor
% endfor


  // Solver registration
% for name, _, arg_types in solver_list:
  % for type_config, ttypes in solver_types.get(name, {}).items():
    <%
    ttype_args = ', '.join(ttypes)
    ttype_symbol = ''.join(map(lambda x: x.replace(' ', ''), ttypes))
    solver_sym = '{}{}<{}>'.format(name, "Cuda", ttype_args)
    solver_typed_sym = '{}{}_{}'.format(name, "Cuda", ttype_symbol)
    %> 
  using ${solver_typed_sym} = ${solver_sym};
  NBLA_REGISTER_SOLVER_IMPL(${name}, ${solver_typed_sym}, "cuda:${type_config}"${''.join(map(lambda x: ', ' + x, arg_types))});
  %endfor  
% endfor

  // Communicator registration
#ifdef FEATURE_DIST_TRAIN
  typedef DataParallelCommunicatorNccl<float> DataParallelCommunicatorNcclf;
  NBLA_REGISTER_COMMUNICATOR_IMPL(DataParallelCommunicator, DataParallelCommunicatorNcclf, "cuda:float");
  typedef MultiProcessDataParallelCommunicatorNccl<float> MultiProcessDataParallelCommunicatorNcclf;
  NBLA_REGISTER_COMMUNICATOR_IMPL(MultiProcessDataParallelCommunicator, MultiProcessDataParallelCommunicatorNcclf, "cuda:float");

  typedef DataParallelCommunicatorNccl<Half> DataParallelCommunicatorNcclh;
  NBLA_REGISTER_COMMUNICATOR_IMPL(DataParallelCommunicator, DataParallelCommunicatorNcclh, "cuda:half");
  typedef MultiProcessDataParallelCommunicatorNccl<Half> MultiProcessDataParallelCommunicatorNcclh;
  NBLA_REGISTER_COMMUNICATOR_IMPL(MultiProcessDataParallelCommunicator, MultiProcessDataParallelCommunicatorNcclh, "cuda:half");

#endif

  is_initialized = true;
}

void clear_cuda_memory_cache() {
  SingletonManager::get<Cuda>()->caching_allocator()->free_unused_caches();
}

void print_cuda_memory_cache_map() {
  SingletonManager::get<Cuda>()->caching_allocator()->print_memory_cache_map();
}

size_t get_cuda_caching_allocator_fragmentation_bytes(const string& device_id) {
  return SingletonManager::get<Cuda>()->caching_allocator()->get_fragmentation_bytes(device_id);
}

size_t get_cuda_caching_allocator_max_available_bytes(const string& device_id) {
  return SingletonManager::get<Cuda>()->caching_allocator()->get_max_available_bytes(device_id);
}

vector<int> get_cuda_cached_memory_used_counts(const string& device_id) {
  return SingletonManager::get<Cuda>()->caching_allocator()->get_used_memory_counts(device_id);
}

#if CUDA_VERSION >= 10020 && CUDNN_VERSION >= 8000
void clear_cuda_virtual_memory_cache() {
  SingletonManager::get<Cuda>()->virtual_caching_allocator()->free_unused_caches();
}

void print_cuda_virtual_memory_cache_map() {
  SingletonManager::get<Cuda>()->virtual_caching_allocator()->print_memory_cache_map();
}

size_t get_cuda_virtual_caching_allocator_fragmentation_bytes(const string& device_id) {
  return SingletonManager::get<Cuda>()->virtual_caching_allocator()->get_fragmentation_bytes(device_id);
}

size_t get_cuda_virtual_caching_allocator_max_available_bytes(const string& device_id) {
  return SingletonManager::get<Cuda>()->virtual_caching_allocator()->get_max_available_bytes(device_id);
}

vector<int> get_cuda_virtual_memory_used_counts(const string& device_id) {
  return SingletonManager::get<Cuda>()->virtual_caching_allocator()->get_used_memory_counts(device_id);
}
#else
// dummy functions for cython.
void clear_cuda_virtual_memory_cache() {}

void print_cuda_virtual_memory_cache_map() {}

size_t get_cuda_virtual_caching_allocator_fragmentation_bytes(const string& device_id) {return 0;}

size_t get_cuda_virtual_caching_allocator_max_available_bytes(const string& device_id) {return 0;}

vector<int> get_cuda_virtual_memory_used_counts(const string& device_id) {return {};}
#endif // CUDA_VERSION >= 10020 && CUDNN_VERSION >= 8000

bool is_cuda_tf32_enabled() {
  const char* tf32_enable = std::getenv("NVIDIA_TF32_OVERRIDE");
  if (!tf32_enable || strcmp(tf32_enable, "0") == 0) return false;
  return true;
}

/** Get CUDA array classes.
*/
vector<string> cuda_array_classes() {
  return SingletonManager::get<Cuda>()->array_classes();
}

/** Set CUDA array classes
*/
void _cuda_set_array_classes(const vector<string> &a) {
  return SingletonManager::get<Cuda>()->_set_array_classes(a);
}

void cuda_device_synchronize(const string &device) {
  cuda_set_device(std::stoi(device));
  NBLA_CUDA_CHECK(cudaDeviceSynchronize());
}

int cuda_get_device_count() {
  int count;
  NBLA_CUDA_CHECK(cudaGetDeviceCount(&count));
  return count;
}

vector<string> cuda_get_devices() {
  int count = cuda_get_device_count();
  vector<string> ret(count);
  for (int i = 0; i < count; ++i) {
    ret[i] = std::to_string(i);
  }
  return ret;
}

shared_ptr<void> cuda_create_stream(int device_id) {
  cuda_set_device(device_id);

  std::default_delete<cudaStream_t> default_deleter;
  auto deleter = [default_deleter](cudaStream_t* ptr) {
      NBLA_CUDA_CHECK(cudaStreamDestroy(*ptr));

      default_deleter(ptr);
  };

  auto stream = shared_ptr<cudaStream_t>(new cudaStream_t(), deleter);

  NBLA_CUDA_CHECK(cudaStreamCreateWithFlags(stream.get(), cudaStreamNonBlocking));

  return stream;
}

void* cuda_stream_shared_to_void(shared_ptr<void> stream) {
  auto s = static_cast<cudaStream_t*>(stream.get());

  return static_cast<void*>(*s);
}

void print_stream_flag (shared_ptr<void> stream) {
  auto s = static_cast<cudaStream_t*>(stream.get());
  unsigned int flags;

  NBLA_CUDA_CHECK(cudaStreamGetFlags(*s, &flags));
  printf("flags: %u\n", flags);
}

void print_stream_priority (shared_ptr<void> stream) {
  auto s = static_cast<cudaStream_t*>(stream.get());
  int p;

  NBLA_CUDA_CHECK(cudaStreamGetPriority(*s, &p));
  printf("priority: %d\n", p);
}

void cuda_nullstream_synchronize() {
  NBLA_CUDA_CHECK(cudaStreamSynchronize(0));
}

void cuda_stream_synchronize(shared_ptr<void> stream) {
  auto s = static_cast<cudaStream_t*>(stream.get());
  NBLA_CUDA_CHECK(cudaStreamSynchronize(*s));
}

void cuda_stream_destroy(shared_ptr<void> stream) {
  auto s = static_cast<cudaStream_t*>(stream.get());

  NBLA_CUDA_CHECK(cudaStreamDestroy(*s));
}

std::shared_ptr<void> cuda_create_event(int device_id, unsigned int flags) {
  cuda_set_device(device_id);

  std::default_delete<cudaEvent_t> default_deleter;
  auto deleter = [default_deleter](cudaEvent_t* ptr) {
      NBLA_CUDA_CHECK(cudaEventDestroy(*ptr));

      default_deleter(ptr);
  };

  auto event = shared_ptr<cudaEvent_t>(new cudaEvent_t(), deleter);

  NBLA_CUDA_CHECK(cudaEventCreateWithFlags(event.get(), flags));

  return event;
}

void cuda_default_stream_event(shared_ptr<void> event){
  auto e = static_cast<cudaEvent_t*>(event.get());

  NBLA_CUDA_CHECK(cudaEventRecord(*e));

}
void cuda_stream_wait_event(shared_ptr<void> stream, shared_ptr<void> event) {
  auto s = static_cast<cudaStream_t*>(stream.get());
  auto e = static_cast<cudaEvent_t*>(event.get());

  NBLA_CUDA_CHECK(cudaStreamWaitEvent(*s, *e, 0));

}

void cuda_event_synchronize(shared_ptr<void> event) {
  auto e = static_cast<cudaEvent_t*>(event.get());

  NBLA_CUDA_CHECK(cudaEventSynchronize(*e));
}

void cuda_event_record(shared_ptr<void> event) {
  auto event_ptr = (cudaEvent_t*)(event.get());

  NBLA_CUDA_CHECK(cudaEventRecord(*event_ptr));
}

float cuda_event_elapsed_time(shared_ptr<void> event_s, shared_ptr<void> event_e) {
  auto event_s_ptr = (cudaEvent_t*)(event_s.get());
  auto event_e_ptr = (cudaEvent_t*)(event_e.get());

  float milliseconds = 0;

  NBLA_CUDA_CHECK(cudaEventElapsedTime(&milliseconds, *event_s_ptr, *event_e_ptr));

  return milliseconds;
}

void set_cuda_vma_chunk_size(size_t size) {
  SingletonManager::get<Cuda>()->set_vma_chunk_size(size);
}

}
